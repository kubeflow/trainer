{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Kubeflow Trainer: Local Training\n",
    "\n",
    "This notebook demonstrates how to run single-node training using the **Local Process Backend**.\n",
    "\n",
    "## Local Process Backend\n",
    "\n",
    "- **Container Runtime**: None (native Python subprocess)\n",
    "- **Use Case**: Quick testing, debugging, rapid iteration\n",
    "- **Prerequisites**: Python 3.9+ only\n",
    "\n",
    "This example trains a CNN on the classic [MNIST](http://yann.lecun.com/exdb/mnist/) handwritten digit dataset using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install",
   "metadata": {},
   "source": [
    "## Install the Kubeflow SDK\n",
    "\n",
    "You need to install the Kubeflow SDK to interact with Kubeflow Trainer APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pip-install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kubeflow in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: kubeflow-katib-api>=0.19.0 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubeflow) (0.19.0)\n",
      "Requirement already satisfied: kubeflow-trainer-api>=2.0.0 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubeflow) (2.1.0)\n",
      "Requirement already satisfied: kubernetes>=27.2.0 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubeflow) (32.0.1)\n",
      "Requirement already satisfied: pydantic>=2.10.0 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubeflow) (2.11.5)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=27.2.0->kubeflow) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=27.2.0->kubeflow) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=27.2.0->kubeflow) (2.9.0.post0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=27.2.0->kubeflow) (6.0.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=27.2.0->kubeflow) (2.40.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=27.2.0->kubeflow) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=27.2.0->kubeflow) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=27.2.0->kubeflow) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=27.2.0->kubeflow) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=27.2.0->kubeflow) (2.4.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=27.2.0->kubeflow) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=27.2.0->kubeflow) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=27.2.0->kubeflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=27.2.0->kubeflow) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=27.2.0->kubeflow) (0.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.10.0->kubeflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.10.0->kubeflow) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.10.0->kubeflow) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.10.0->kubeflow) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kubernetes>=27.2.0->kubeflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ishti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kubernetes>=27.2.0->kubeflow) (3.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain-core (c:\\Users\\ishti\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (c:\\Users\\ishti\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain-core (c:\\Users\\ishti\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to install\n",
    "# %pip install -U kubeflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-function",
   "metadata": {},
   "source": [
    "## Define the Training Function\n",
    "\n",
    "The first step is to create a function to train CNN model using MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "train-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist():\n",
    "    import torch\n",
    "    import torch.nn.functional as F\n",
    "    from torch import nn, optim\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torchvision import datasets, transforms\n",
    "\n",
    "    # Define the PyTorch CNN model to be trained\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "            self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "            self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
    "            self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = F.max_pool2d(x, 2, 2)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = F.max_pool2d(x, 2, 2)\n",
    "            x = x.view(-1, 4 * 4 * 50)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "    # Create the model\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    model = Net().to(device)\n",
    "    model=torch.compile(model)\n",
    "    \n",
    "    # Load MNIST dataset\n",
    "    dataset = datasets.MNIST(\n",
    "        './data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    )\n",
    "    train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "    \n",
    "    for epoch in range(1, 3):\n",
    "        model.train()\n",
    "        \n",
    "        # Iterate over mini-batches from the training set\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Forward pass\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = F.nll_loss(outputs, target)\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\n",
    "                    \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                        epoch,\n",
    "                        batch_idx * len(data),\n",
    "                        len(train_loader.dataset),\n",
    "                        100.0 * batch_idx / len(train_loader),\n",
    "                        loss.item(),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "    print(\"Training is finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configure-backend",
   "metadata": {},
   "source": [
    "## Configure Local Process Backend\n",
    "\n",
    "Initialize the Local Process Backend configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "backend-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.trainer import TrainerClient, LocalProcessBackendConfig\n",
    "\n",
    "# Configure Local Process Backend\n",
    "backend_config = LocalProcessBackendConfig(\n",
    "    cleanup_venv=True  # Auto-cleanup virtual environments after job completes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "init-client",
   "metadata": {},
   "source": [
    "## Initialize Client\n",
    "\n",
    "Initialize the TrainerClient with the Local Process Backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "create-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = TrainerClient(backend_config=backend_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "list-runtimes",
   "metadata": {},
   "source": [
    "## List the Training Runtimes\n",
    "\n",
    "You can get the list of available Training Runtimes to start your TrainJob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "get-runtimes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime(name='torch-distributed', trainer=RuntimeTrainer(trainer_type=<TrainerType.CUSTOM_TRAINER: 'CustomTrainer'>, framework='torch', image='local', num_nodes=1, device='Unknown', device_count='Unknown'), pretrained_model=None)\n"
     ]
    }
   ],
   "source": [
    "for runtime in client.list_runtimes():\n",
    "    print(runtime)\n",
    "    if runtime.name == \"torch-distributed\":\n",
    "        torch_runtime = runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "start-training",
   "metadata": {},
   "source": [
    "## Run the TrainJob\n",
    "\n",
    "Submit the training job to the Local Process Backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "train-job",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.trainer import CustomTrainer\n",
    "\n",
    "job_name = client.train(\n",
    "    trainer=CustomTrainer(\n",
    "        func=train_mnist,\n",
    "        packages_to_install=[\"pip-system-certs\", \"torch\", \"torchvision\"],\n",
    "    ),\n",
    "    runtime=torch_runtime,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "check-status",
   "metadata": {},
   "source": [
    "## Check the TrainJob Status\n",
    "\n",
    "You can check the status of the TrainJob that's created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "job-status",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job: k4a8652e01ec, Status: Running\n"
     ]
    }
   ],
   "source": [
    "job = client.get_job(job_name)\n",
    "print(\"Job: {}, Status: {}\".format(job.name, job.status))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stream-logs",
   "metadata": {},
   "source": [
    "## Watch the TrainJob Logs\n",
    "\n",
    "We can use the `get_job_logs()` API to get the TrainJob logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logs",
   "metadata": {},
   "outputs": [],
   "source": [
    "for logline in client.get_job_logs(job_name, follow=True):\n",
    "    print(logline, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": [
    "## Delete the TrainJob\n",
    "\n",
    "When the TrainJob is finished, you can delete the resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "delete",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_job(job_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
