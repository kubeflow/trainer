{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PyTorch Speech Recognition with Kubeflow Trainer\n",
                "\n",
                "This example demonstrates how to train a speech recognition model using the [Google Speech Commands](https://www.tensorflow.org/datasets/catalog/speech_commands) dataset and PyTorch Distributed Data Parallel (DDP).\n",
                "\n",
                "It follows a development workflow designed for scale:\n",
                "1. **Define**: Wrap training logic in a self-contained function.\n",
                "2. **Test Locally**: Run the function in a local subprocess to verify code correctness.\n",
                "3. **Scale Distributed**: Submit the same function as a distributed `TrainJob` to a Kubernetes cluster."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Installation\n",
                "\n",
                "Install the Kubeflow Trainer SDK and the model dependencies (PyTorch, Torchaudio, etc)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\Sneha Das\\Desktop\\trainer-1\\.venv\\Lib\\site-packages)\n",
                        "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\Sneha Das\\Desktop\\trainer-1\\.venv\\Lib\\site-packages)\n",
                        "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\Sneha Das\\Desktop\\trainer-1\\.venv\\Lib\\site-packages)\n",
                        "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\Sneha Das\\Desktop\\trainer-1\\.venv\\Lib\\site-packages)\n",
                        "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\Sneha Das\\Desktop\\trainer-1\\.venv\\Lib\\site-packages)\n",
                        "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\Sneha Das\\Desktop\\trainer-1\\.venv\\Lib\\site-packages)\n"
                    ]
                }
            ],
            "source": [
                "# Install Kubeflow Trainer SDK (Development Mode)\n",
                "# If you are not developing the SDK, use: pip install kubeflow-trainer\n",
                "!pip install -q -e ../../../api/python_api\n",
                "\n",
                "# Install model dependencies\n",
                "!pip install -q torch torchaudio librosa soundfile tensorboard"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Define Training Function\n",
                "\n",
                "We define `train_speech_recognition` to encapsulate the entire training loop.\n",
                "\n",
                "**Critical Requirement**: This function must be self-contained. It must import all necessary libraries inside itself because it will be serialized and executed in an isolated environment (container or subprocess)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_speech_recognition():\n",
                "    \"\"\"\n",
                "    Trains an Audio Transformer on the Speech Commands dataset using PyTorch DDP.\n",
                "    \"\"\"\n",
                "    import os\n",
                "    import torch\n",
                "    import torch.nn as nn\n",
                "    import torch.distributed as dist\n",
                "    from torch.nn.parallel import DistributedDataParallel as DDP\n",
                "    from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
                "    import torchaudio\n",
                "    import random\n",
                "    from pathlib import Path\n",
                "    import platform\n",
                "\n",
                "    # Suppress warnings and progress bars for cleaner output\n",
                "    import warnings\n",
                "    warnings.filterwarnings('ignore')\n",
                "    os.environ['TORCHAUDIO_DOWNLOAD_PROGRESS'] = '0'\n",
                "\n",
                "    # --- 1. Environment & Configuration ---\n",
                "    # Detect if we are running on Windows (Local) or Linux (Cluster/Container)\n",
                "    if platform.system() == 'Windows':\n",
                "        data_path = Path(\"C:/data\")\n",
                "        output_dir = Path(\"C:/output\")\n",
                "    else:\n",
                "        data_path = Path.home() / \"data\"\n",
                "        output_dir = Path.home() / \"output\"\n",
                "    \n",
                "    data_path.mkdir(parents=True, exist_ok=True)\n",
                "    output_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "    # Hyperparameters\n",
                "    BATCH_SIZE = 32\n",
                "    EPOCHS = 3\n",
                "    LR = 0.001\n",
                "\n",
                "    # --- 2. DDP Initialization ---\n",
                "    def setup_ddp():\n",
                "        \"\"\"Initializes the distributed process group (NCCL for GPU, Gloo for CPU).\"\"\"\n",
                "        if all(k in os.environ for k in [\"LOCAL_RANK\", \"RANK\", \"WORLD_SIZE\"]):\n",
                "            local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
                "            rank = int(os.environ[\"RANK\"])\n",
                "            world_size = int(os.environ[\"WORLD_SIZE\"])\n",
                "            \n",
                "            if torch.cuda.is_available():\n",
                "                backend = \"nccl\"\n",
                "                device = torch.device(\"cuda\", local_rank)\n",
                "                torch.cuda.set_device(device)\n",
                "            else:\n",
                "                backend = \"gloo\"\n",
                "                device = torch.device(\"cpu\")\n",
                "            \n",
                "            dist.init_process_group(backend=backend)\n",
                "            print(f\"[Rank {rank}/{world_size}] DDP Initialized using {backend}\")\n",
                "            return device, local_rank, rank, world_size\n",
                "        else:\n",
                "            print(\"[Single Process] DDP variables not found. Running in standalone mode.\")\n",
                "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "            return device, 0, 0, 1\n",
                "\n",
                "    def cleanup_ddp():\n",
                "        if dist.is_initialized():\n",
                "            dist.destroy_process_group()\n",
                "\n",
                "    # --- 3. Model Architecture ---\n",
                "    class AudioTransformer(nn.Module):\n",
                "        def __init__(self, num_classes=35, d_model=128, nhead=4, num_layers=2):\n",
                "            super().__init__()\n",
                "            self.encoder = nn.TransformerEncoder(\n",
                "                nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True),\n",
                "                num_layers=num_layers\n",
                "            )\n",
                "            self.classifier = nn.Linear(d_model, num_classes)\n",
                "\n",
                "        def forward(self, x):\n",
                "            # Input: (batch, n_mels, time) -> Permute to (batch, time, n_mels) for Transformer\n",
                "            x = x.permute(0, 2, 1)\n",
                "            x = self.encoder(x)\n",
                "            # Simple global average pooling\n",
                "            x = x.mean(dim=1)\n",
                "            return self.classifier(x)\n",
                "\n",
                "    # --- 4. Dataset Wrapper ---\n",
                "    class SpeechDataset(Dataset):\n",
                "        def __init__(self, audio_paths, label_map):\n",
                "            self.audio_paths = audio_paths\n",
                "            self.label_map = label_map\n",
                "            self.transform = torchaudio.transforms.MelSpectrogram(n_mels=128)\n",
                "\n",
                "        def __len__(self): \n",
                "            return len(self.audio_paths)\n",
                "\n",
                "        def __getitem__(self, idx):\n",
                "            try:\n",
                "                path, label = self.audio_paths[idx]\n",
                "                waveform, _ = torchaudio.load(path)\n",
                "                # Ensure fixed length (1 second @ 16kHz)\n",
                "                target_len = 16000\n",
                "                if waveform.size(1) < target_len:\n",
                "                    waveform = torch.nn.functional.pad(waveform, (0, target_len - waveform.size(1)))\n",
                "                else:\n",
                "                    waveform = waveform[:, :target_len]\n",
                "                \n",
                "                spec = self.transform(waveform).squeeze(0)\n",
                "                return spec, self.label_map[label]\n",
                "            except Exception as e:\n",
                "                print(f\"Error loading audio file: {e}\")\n",
                "                return torch.zeros(128, 81), 0  # Fallback for corrupted files\n",
                "\n",
                "    def collate_fn(batch):\n",
                "        specs, labels = zip(*batch)\n",
                "        return torch.stack(specs), torch.tensor(labels, dtype=torch.long)\n",
                "\n",
                "    # --- 5. Main Training Logic ---\n",
                "    try:\n",
                "        device, local_rank, rank, world_size = setup_ddp()\n",
                "\n",
                "        # --- Data Prep ---\n",
                "        # Only Rank 0 downloads the data to the shared volume/cache\n",
                "        if rank == 0:\n",
                "            print(\"Verifying/Downloading dataset...\")\n",
                "            torchaudio.datasets.SPEECHCOMMANDS(root=str(data_path), download=True)\n",
                "        \n",
                "        if dist.is_initialized():\n",
                "            dist.barrier()  # Wait for download to finish\n",
                "\n",
                "        # Load file list manually for flexibility\n",
                "        data_root = data_path / \"SpeechCommands\" / \"speech_commands_v0.02\"\n",
                "        labels = sorted([d.name for d in data_root.iterdir() if d.is_dir() and not d.name.startswith(\"_\")])\n",
                "        label_map = {l: i for i, l in enumerate(labels)}\n",
                "        \n",
                "        all_files = []\n",
                "        for label in labels:\n",
                "            for f in (data_root / label).glob(\"*.wav\"):\n",
                "                all_files.append((str(f), label))\n",
                "        \n",
                "        # Subset for faster demonstration\n",
                "        random.shuffle(all_files)\n",
                "        train_files = all_files[:1000]\n",
                "\n",
                "        # DDP Sampler handles data sharding across nodes\n",
                "        dataset = SpeechDataset(train_files, label_map)\n",
                "        sampler = DistributedSampler(dataset) if dist.is_initialized() else None\n",
                "        loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=sampler, \n",
                "                          shuffle=(sampler is None), collate_fn=collate_fn, num_workers=0)\n",
                "\n",
                "        # --- Model & Optimizer ---\n",
                "        model = AudioTransformer(num_classes=len(labels)).to(device)\n",
                "        if dist.is_initialized():\n",
                "            model = DDP(model, device_ids=[local_rank] if torch.cuda.is_available() else None)\n",
                "\n",
                "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
                "        criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "        # --- Training Loop ---\n",
                "        print(f\"[Rank {rank}] Starting training on {len(labels)} classes...\")\n",
                "        for epoch in range(1, EPOCHS + 1):\n",
                "            model.train()\n",
                "            if sampler: \n",
                "                sampler.set_epoch(epoch)\n",
                "            \n",
                "            total_loss = 0.0\n",
                "            for i, (data, target) in enumerate(loader):\n",
                "                data, target = data.to(device), target.to(device)\n",
                "                optimizer.zero_grad()\n",
                "                output = model(data)\n",
                "                loss = criterion(output, target)\n",
                "                loss.backward()\n",
                "                optimizer.step()\n",
                "                total_loss += loss.item()\n",
                "            \n",
                "            avg_loss = total_loss / len(loader)\n",
                "            if rank == 0:\n",
                "                print(f\"Epoch {epoch}/{EPOCHS} | Loss: {avg_loss:.4f}\")\n",
                "\n",
                "        # Save model (only rank 0)\n",
                "        if rank == 0:\n",
                "            model_path = output_dir / \"speech_model.pt\"\n",
                "            if dist.is_initialized():\n",
                "                torch.save(model.module.state_dict(), model_path)\n",
                "            else:\n",
                "                torch.save(model.state_dict(), model_path)\n",
                "            print(f\"Model saved to {model_path}\")\n",
                "\n",
                "        cleanup_ddp()\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"[Error] Training failed: {e}\")\n",
                "        import traceback\n",
                "        traceback.print_exc()\n",
                "        cleanup_ddp()\n",
                "        raise"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run Training Locally\n",
                "\n",
                "Before scaling to a cluster, we test the code locally using the `TrainerClient`. We use the `torch-distributed` runtime which creates a local DDP environment (simulating a cluster node)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting local training...\n",
                        "Note: First run will download the dataset (~2GB), which may take a few minutes.\n",
                        "\n",
                        "Job o986a4180f2d started. Streaming logs...\n",
                        "\n",
                        "T\u0000h\u0000e\u0000 \u0000R\u0000P\u0000C\u0000 \u0000c\u0000a\u0000l\u0000l\u0000 \u0000c\u0000o\u0000n\u0000t\u0000a\u0000i\u0000n\u0000s\u0000 \u0000a\u0000 \u0000h\u0000a\u0000n\u0000d\u0000l\u0000e\u0000 \u0000t\u0000h\u0000a\u0000t\u0000 \u0000d\u0000i\u0000f\u0000f\u0000e\u0000r\u0000s\u0000 \u0000f\u0000r\u0000o\u0000m\u0000 \u0000t\u0000h\u0000e\u0000 \u0000d\u0000e\u0000c\u0000l\u0000a\u0000r\u0000e\u0000d\u0000 \u0000h\u0000a\u0000n\u0000d\u0000l\u0000e\u0000 \u0000t\u0000y\u0000p\u0000e\u0000.\u0000 \u0000\n",
                        "\u0000\n",
                        "\u0000E\u0000r\u0000r\u0000o\u0000r\u0000 \u0000c\u0000o\u0000d\u0000e\u0000:\u0000 \u0000B\u0000a\u0000s\u0000h\u0000/\u0000S\u0000e\u0000r\u0000v\u0000i\u0000c\u0000e\u0000/\u00000\u0000x\u00008\u00000\u00000\u00007\u00000\u00007\u00002\u0000c\u0000\n",
                        "\u0000\n",
                        "\u0000[o986a4180f2d-train] Completed with code 1 in 0:00:00.147117 seconds.T\u0000h\u0000e\u0000 \u0000R\u0000P\u0000C\u0000 \u0000c\u0000a\u0000l\u0000l\u0000 \u0000c\u0000o\u0000n\u0000t\u0000a\u0000i\u0000n\u0000s\u0000 \u0000a\u0000 \u0000h\u0000a\u0000n\u0000d\u0000l\u0000e\u0000 \u0000t\u0000h\u0000a\u0000t\u0000 \u0000d\u0000i\u0000f\u0000f\u0000e\u0000r\u0000s\u0000 \u0000f\u0000r\u0000o\u0000m\u0000 \u0000t\u0000h\u0000e\u0000 \u0000d\u0000e\u0000c\u0000l\u0000a\u0000r\u0000e\u0000d\u0000 \u0000h\u0000a\u0000n\u0000d\u0000l\u0000e\u0000 \u0000t\u0000y\u0000p\u0000e\u0000.\u0000 \u0000\u0000\u0000E\u0000r\u0000r\u0000o\u0000r\u0000 \u0000c\u0000o\u0000d\u0000e\u0000:\u0000 \u0000B\u0000a\u0000s\u0000h\u0000/\u0000S\u0000e\u0000r\u0000v\u0000i\u0000c\u0000e\u0000/\u00000\u0000x\u00008\u00000\u00000\u00007\u00000\u00007\u00002\u0000c\u0000\u0000\u0000[o986a4180f2d-train] Completed with code 1 in 0:00:00.147117 seconds."
                    ]
                }
            ],
            "source": [
                "from kubeflow.trainer import CustomTrainer, TrainerClient, LocalProcessBackendConfig\n",
                "\n",
                "# Initialize the client with LocalProcessBackend to run locally\n",
                "client = TrainerClient(\n",
                "    backend_config=LocalProcessBackendConfig(cleanup_venv=True)\n",
                ")\n",
                "\n",
                "# Retrieve the 'torch-distributed' runtime object from the client's registry\n",
                "local_runtime = None\n",
                "for runtime in client.list_runtimes():\n",
                "    if runtime.name == \"torch-distributed\":\n",
                "        local_runtime = runtime\n",
                "        break\n",
                "\n",
                "if not local_runtime:\n",
                "    raise ValueError(\"Local runtime 'torch-distributed' not found\")\n",
                "\n",
                "print(\"Starting local training...\")\n",
                "print(\"Note: First run will download the dataset (~2GB), which may take a few minutes.\\n\")\n",
                "\n",
                "# Start training\n",
                "local_job_name = client.train(\n",
                "    trainer=CustomTrainer(\n",
                "        func=train_speech_recognition,\n",
                "        # Libraries to install in the local virtual environment\n",
                "        packages_to_install=[\"torch\", \"torchaudio\", \"librosa\", \"soundfile\", \"tensorboard\"],\n",
                "    ),\n",
                "    runtime=local_runtime, \n",
                ")\n",
                "\n",
                "# Stream logs\n",
                "print(f\"Job {local_job_name} started. Streaming logs...\\n\")\n",
                "try:\n",
                "    for logline in client.get_job_logs(local_job_name, follow=True):\n",
                "        print(logline, end='')\n",
                "except KeyboardInterrupt:\n",
                "    print(\"\\n\\nLog streaming interrupted by user.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Distributed Training (Kubernetes)\n",
                "\n",
                "Now we scale the job to a Kubernetes cluster. This requires:\n",
                "1. A Kubernetes cluster with the **Kubeflow Training Operator** installed.\n",
                "2. The **TrainingRuntime** CRD (`torch-distributed`) installed on the cluster.\n",
                "3. Access via `~/.kube/config`.\n",
                "\n",
                "Based on your cluster's resources, we use a minimal configuration."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Submitting distributed TrainJob...\n",
                        "TrainJob 's13cdaf8c7b2' submitted successfully!\n",
                        "\n",
                        "You can check the job status with: kubectl get trainjobs s13cdaf8c7b2\n"
                    ]
                }
            ],
            "source": [
                "from kubeflow.trainer import CustomTrainer, TrainerClient\n",
                "\n",
                "# Initialize client (automatically loads ~/.kube/config)\n",
                "client = TrainerClient()\n",
                "\n",
                "print(\"Submitting distributed TrainJob...\")\n",
                "\n",
                "try:\n",
                "    k8s_job_name = client.train(\n",
                "        trainer=CustomTrainer(\n",
                "            func=train_speech_recognition,\n",
                "            num_nodes=1,  # Start with 1 node (can scale to 3 if resources allow)\n",
                "            resources_per_node={\n",
                "                \"cpu\": \"2\",\n",
                "                \"memory\": \"4Gi\",\n",
                "                # \"nvidia.com/gpu\": \"1\",  # Uncomment for GPU training\n",
                "            },\n",
                "            packages_to_install=[\"torch\", \"torchaudio\", \"librosa\", \"soundfile\", \"tensorboard\"],\n",
                "        ),\n",
                "        runtime=\"torch-distributed\",  # Matches the TrainingRuntime on the cluster\n",
                "    )\n",
                "    print(f\"TrainJob '{k8s_job_name}' submitted successfully!\")\n",
                "    print(f\"\\nYou can check the job status with: kubectl get trainjobs {k8s_job_name}\")\n",
                "\n",
                "except Exception as e:\n",
                "    print(f\"Failed to submit TrainJob: {e}\")\n",
                "    import traceback\n",
                "    traceback.print_exc()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Check Status & Logs\n",
                "\n",
                "Verify the job status and view real-time logs from the master replica."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "NAME           STATE      AGE\n",
                        "c5cb3f1787ac   Complete   26m\n",
                        "l29bae43c5be   Complete   75m\n",
                        "s13cdaf8c7b2              1s\n",
                        "NAME                          READY   STATUS              RESTARTS   AGE\n",
                        "c5cb3f1787ac-node-0-0-9rpgk   0/1     Completed           0          26m\n",
                        "l29bae43c5be-node-0-0-jr5rf   0/1     Completed           0          75m\n",
                        "s13cdaf8c7b2-node-0-0-g2ns4   0/1     ContainerCreating   0          0s\n"
                    ]
                }
            ],
            "source": [
                "!kubectl get trainjobs\n",
                "!kubectl get pods"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Waiting for job s13cdaf8c7b2 to start running...\n",
                        "Job is running! Streaming logs...\n",
                        "\n",
                        "100%|██████████| 2.26G/2.26G [22:03<00:00, 1.84MB/s]  one, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/librosa/WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.W0208 08:30:19.818000 1 site-packages/torch/distributed/run.py:803] W0208 08:30:19.818000 1 site-packages/torch/distributed/run.py:803] *****************************************W0208 08:30:19.818000 1 site-packages/torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. W0208 08:30:19.818000 1 site-packages/torch/distributed/run.py:803] *****************************************[Gloo] Rank [Gloo] Rank 0 is connected to 11 is connected to  peer ranks. 1Expected number of connected peer ranks is :  peer ranks. 1Expected number of connected peer ranks is : 1[Rank 0/2] DDP Initialized using gloo[Rank 1/2] DDP Initialized using glooVerifying/Downloading dataset...[Error] Training failed: [/pytorch/third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:78] Timed out waiting 1800000ms for recv operation to completeTraceback (most recent call last):  File \"/workspace/2486715667.py\", line 126, in train_speech_recognition    dist.barrier()  # Wait for download to finish    ^^^^^^^^^^^^^^  File \"/opt/conda/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 81, in wrapper    return func(*args, **kwargs)           ^^^^^^^^^^^^^^^^^^^^^  File \"/opt/conda/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py\", line 4888, in barrier    work.wait()RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:78] Timed out waiting 1800000ms for recv operation to complete[rank1]: Traceback (most recent call last):[rank1]:   File \"/workspace/2486715667.py\", line 195, in <module>[rank1]:     train_speech_recognition()[rank1]:   File \"/workspace/2486715667.py\", line 126, in train_speech_recognition[rank1]:     dist.barrier()  # Wait for download to finish[rank1]:     ^^^^^^^^^^^^^^[rank1]:   File \"/opt/conda/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 81, in wrapper[rank1]:     return func(*args, **kwargs)[rank1]:            ^^^^^^^^^^^^^^^^^^^^^[rank1]:   File \"/opt/conda/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py\", line 4888, in barrier[rank1]:     work.wait()[rank1]: RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:78] Timed out waiting 1800000ms for recv operation to completeW0208 09:02:14.062000 1 site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 23 closing signal SIGTERME0208 09:02:17.149000 1 site-packages/torch/distributed/elastic/multiprocessing/api.py:882] failed (exitcode: 1) local_rank: 1 (pid: 24) of binary: /opt/conda/bin/python3.11Traceback (most recent call last):  File \"/opt/conda/bin/torchrun\", line 7, in <module>    sys.exit(main())             ^^^^^^  File \"/opt/conda/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 357, in wrapper    return f(*args, **kwargs)           ^^^^^^^^^^^^^^^^^^  File \"/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py\", line 936, in main    run(args)  File \"/opt/conda/lib/python3.11/site-packages/torch/distributed/run.py\", line 927, in run    elastic_launch(  File \"/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 156, in __call__    return launch_agent(self._config, self._entrypoint, list(args))           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"/opt/conda/lib/python3.11/site-packages/torch/distributed/launcher/api.py\", line 293, in launch_agent    raise ChildFailedError(torch.distributed.elastic.multiprocessing.errors.ChildFailedError: ============================================================2486715667.py FAILED------------------------------------------------------------Failures:  <NO_OTHER_FAILURES>------------------------------------------------------------Root Cause (first observed failure):[0]:  time      : 2026-02-08_09:02:13  host      : s13cdaf8c7b2-node-0-0.s13cdaf8c7b2.default.svc.cluster.local  rank      : 1 (local_rank: 1)  exitcode  : 1 (pid: 24)  error_file: <N/A>  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html============================================================"
                    ]
                }
            ],
            "source": [
                "# Only run this cell if you successfully created a Kubernetes job in the previous step\n",
                "if 'k8s_job_name' in locals():\n",
                "    print(f\"Waiting for job {k8s_job_name} to start running...\")\n",
                "    \n",
                "    try:\n",
                "        # Wait for the running status\n",
                "        client.wait_for_job_status(name=k8s_job_name, status={\"Running\"}, timeout=300)\n",
                "        \n",
                "        print(f\"Job is running! Streaming logs...\\n\")\n",
                "        for logline in client.get_job_logs(k8s_job_name, follow=True):\n",
                "            print(logline, end='')\n",
                "    except KeyboardInterrupt:\n",
                "        print(\"\\n\\nLog streaming interrupted by user.\")\n",
                "    except Exception as e:\n",
                "        print(f\"\\nError while waiting for job or streaming logs: {e}\")\n",
                "        print(f\"You can manually check logs with: kubectl logs -f {k8s_job_name}-node-0-0-<pod-id>\")\n",
                "else:\n",
                "    print(\"No Kubernetes job found. Please run the previous cell to create a job first.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
