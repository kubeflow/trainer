{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Audio Classification with PyTorch and Kubeflow Trainer\n",
                "\n",
                "This example demonstrates how to train a CNN for audio classification using the GTZAN dataset and PyTorch Distributed Data Parallel (DDP).\n",
                "\n",
                "It follows a development workflow designed for scale:\n",
                "1. **Define**: Wrap training logic in a self-contained function.\n",
                "2. **Test Locally**: Run the function in a local subprocess to verify code correctness.\n",
                "3. **Scale Distributed**: Submit the same function as a distributed `TrainJob` to a Kubernetes cluster."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Installation\n",
                "\n",
                "You need to install the Kubeflow SDK to interact with Kubeflow Trainer APIs:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "56369386",
            "metadata": {},
            "outputs": [],
            "source": [
                "# !pip install -U kubeflow"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e7e13ca2",
            "metadata": {},
            "source": [
                "Install the model dependencies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "15c0d678",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install model dependencies\n",
                "!pip install -q torch torchaudio soundfile kagglehub numpy"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a4849647",
            "metadata": {},
            "source": [
                "## 2. Define Training Function\n",
                "\n",
                "We define `train_audio_classification` to encapsulate the entire training loop.\n",
                "\n",
                "**Critical Requirement**: This function must be self-contained. It must import all necessary libraries inside itself because it will be serialized and executed in an isolated environment (container or subprocess)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5ee1a914",
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_audio_classification():\n",
                "    \"\"\"\n",
                "    Trains a CNN on the GTZAN audio dataset using PyTorch DDP.\n",
                "    \"\"\"\n",
                "    import os\n",
                "    import shutil\n",
                "    from pathlib import Path\n",
                "    import numpy as np\n",
                "    import torch\n",
                "    import torch.nn as nn\n",
                "    import torch.optim as optim\n",
                "    import torch.distributed as dist\n",
                "    from torch.nn.parallel import DistributedDataParallel as DDP\n",
                "    from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
                "    from torchaudio.transforms import MelSpectrogram\n",
                "    import soundfile as sf\n",
                "    import platform\n",
                "\n",
                "    # Suppress warnings and progress bars for cleaner output\n",
                "    import warnings\n",
                "    warnings.filterwarnings('ignore')\n",
                "    os.environ['KAGGLE_DOWNLOAD_PROGRESS'] = '0'\n",
                "\n",
                "    # --- 1. Environment & Configuration ---\n",
                "    # Detect if we are running on Windows (Local) or Linux (Cluster/Container)\n",
                "    if platform.system() == 'Windows':\n",
                "        data_dir = Path(\"C:/data/gtzan\")\n",
                "        output_dir = Path(\"C:/output\")\n",
                "    else:\n",
                "        data_dir = Path.home() / \"data\" / \"gtzan\"\n",
                "        output_dir = Path.home() / \"output\"\n",
                "    \n",
                "    data_dir.mkdir(parents=True, exist_ok=True)\n",
                "    output_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "    # Hyperparameters\n",
                "    BATCH_SIZE = 16\n",
                "    EPOCHS = 5\n",
                "    LR = 1e-3\n",
                "    SAMPLE_RATE = 22050\n",
                "    AUDIO_LENGTH = 3  # seconds\n",
                "    FIXED_LENGTH = SAMPLE_RATE * AUDIO_LENGTH\n",
                "\n",
                "    # --- 2. DDP Initialization ---\n",
                "    def setup_ddp():\n",
                "        \"\"\"Initializes the distributed process group (NCCL for GPU, Gloo for CPU).\"\"\"\n",
                "        if all(k in os.environ for k in [\"LOCAL_RANK\", \"RANK\", \"WORLD_SIZE\"]):\n",
                "            local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
                "            rank = int(os.environ[\"RANK\"])\n",
                "            world_size = int(os.environ[\"WORLD_SIZE\"])\n",
                "            \n",
                "            if torch.cuda.is_available():\n",
                "                backend = \"nccl\"\n",
                "                device = torch.device(\"cuda\", local_rank)\n",
                "                torch.cuda.set_device(device)\n",
                "            else:\n",
                "                backend = \"gloo\"\n",
                "                device = torch.device(\"cpu\")\n",
                "            \n",
                "            dist.init_process_group(backend=backend)\n",
                "            print(f\"[Rank {rank}/{world_size}] DDP Initialized using {backend}\")\n",
                "            return device, local_rank, rank, world_size\n",
                "        else:\n",
                "            print(\"[Single Process] DDP variables not found. Running in standalone mode.\")\n",
                "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "            return device, 0, 0, 1\n",
                "\n",
                "    def cleanup_ddp():\n",
                "        if dist.is_initialized():\n",
                "            dist.destroy_process_group()\n",
                "\n",
                "    # --- 3. Dataset Download Function ---\n",
                "    def download_gtzan_dataset(target_dir):\n",
                "        \"\"\"\n",
                "        Download GTZAN dataset from Kaggle or create mock dataset for testing.\n",
                "        \"\"\"\n",
                "        target_path = Path(target_dir)\n",
                "        \n",
                "        # If target already exists and contains data, skip\n",
                "        if target_path.exists() and any(target_path.iterdir()):\n",
                "            print(f\"Dataset directory {target_dir} already exists. Skipping download.\")\n",
                "            return str(target_path)\n",
                "        \n",
                "        # Try to download from Kaggle\n",
                "        try:\n",
                "            import kagglehub\n",
                "            print(\"Downloading GTZAN dataset from Kaggle...\")\n",
                "            download_path = kagglehub.dataset_download(\n",
                "                \"andradaolteanu/gtzan-dataset-music-genre-classification\"\n",
                "            )\n",
                "            \n",
                "            print(f\"Dataset downloaded successfully.\")\n",
                "            \n",
                "            # The downloaded dataset contains 'genres_original' folder\n",
                "            source_genres_path = Path(download_path) / \"genres_original\"\n",
                "            \n",
                "            # Copy the genres_original folder to our target location\n",
                "            if source_genres_path.exists():\n",
                "                print(f\"Preparing dataset...\")\n",
                "                if target_path.exists():\n",
                "                    shutil.rmtree(target_path)\n",
                "                shutil.copytree(source_genres_path, target_path)\n",
                "                print(f\"Dataset ready at {target_dir}\")\n",
                "                return str(target_path)\n",
                "            else:\n",
                "                raise RuntimeError(f\"genres_original not found in {download_path}\")\n",
                "            \n",
                "        except Exception as e:\n",
                "            print(f\"Unable to download from Kaggle: {e}\")\n",
                "            print(\"Creating mock dataset for testing/demonstration purposes...\")\n",
                "            \n",
                "            # Create a minimal mock dataset with 2 genres and 10 audio files each\n",
                "            target_path.mkdir(parents=True, exist_ok=True)\n",
                "            genres = [\"rock\", \"jazz\"]\n",
                "            \n",
                "            for genre in genres:\n",
                "                genre_path = target_path / genre\n",
                "                genre_path.mkdir(exist_ok=True)\n",
                "                \n",
                "                # Create 10 mock audio files per genre\n",
                "                for i in range(10):\n",
                "                    # Generate 3 seconds of random audio at 22050 Hz\n",
                "                    duration = 3\n",
                "                    sample_rate = 22050\n",
                "                    samples = int(duration * sample_rate)\n",
                "                    \n",
                "                    # Create random audio with some variation based on genre\n",
                "                    if genre == \"rock\":\n",
                "                        audio = np.random.uniform(-0.5, 0.5, samples).astype(np.float32)\n",
                "                    else:\n",
                "                        audio = np.random.uniform(-0.3, 0.3, samples).astype(np.float32)\n",
                "                    \n",
                "                    # Save as WAV file\n",
                "                    wav_path = genre_path / f\"{genre}.{i:05d}.wav\"\n",
                "                    sf.write(str(wav_path), audio, sample_rate)\n",
                "            \n",
                "            print(f\"Mock dataset created at {target_dir} with {len(genres)} genres\")\n",
                "            print(\"NOTE: This is synthetic data for testing.\")\n",
                "            return str(target_path)\n",
                "\n",
                "    # --- 4. Dataset Class ---\n",
                "    class AudioDataset(Dataset):\n",
                "        def __init__(self, root_dir):\n",
                "            self.root = Path(root_dir)\n",
                "\n",
                "            if not self.root.exists() or not self.root.is_dir():\n",
                "                raise RuntimeError(f\"Directory does not exist: {root_dir}\")\n",
                "\n",
                "            self.classes = sorted(\n",
                "                p.name for p in self.root.iterdir()\n",
                "                if p.is_dir() and not p.name.startswith(\".\")\n",
                "            )\n",
                "\n",
                "            if len(self.classes) < 2:\n",
                "                raise RuntimeError(\"Must contain at least two class subdirectories\")\n",
                "\n",
                "            self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
                "\n",
                "            self.files = []\n",
                "            for cls in self.classes:\n",
                "                wavs = list((self.root / cls).glob(\"*.wav\"))\n",
                "                if not wavs:\n",
                "                    raise RuntimeError(f\"No .wav files found in class folder: {cls}\")\n",
                "                self.files.extend(wavs)\n",
                "\n",
                "            self.mel = MelSpectrogram(\n",
                "                sample_rate=SAMPLE_RATE,\n",
                "                n_mels=64\n",
                "            )\n",
                "\n",
                "        def __len__(self):\n",
                "            return len(self.files)\n",
                "\n",
                "        def __getitem__(self, idx):\n",
                "            wav_path = self.files[idx]\n",
                "            label = self.class_to_idx[wav_path.parent.name]\n",
                "\n",
                "            try:\n",
                "                # Load audio using soundfile\n",
                "                waveform, sr = sf.read(str(wav_path))\n",
                "                waveform = torch.FloatTensor(waveform)\n",
                "                \n",
                "                # Handle stereo to mono conversion\n",
                "                if waveform.ndim == 2:\n",
                "                    waveform = waveform.mean(dim=1)\n",
                "                \n",
                "                # Ensure it's 1D then add channel dimension\n",
                "                if waveform.ndim == 1:\n",
                "                    waveform = waveform.unsqueeze(0)\n",
                "                \n",
                "                # Resample if needed\n",
                "                if sr != SAMPLE_RATE:\n",
                "                    import torchaudio.functional as F\n",
                "                    waveform = F.resample(waveform, sr, SAMPLE_RATE)\n",
                "                \n",
                "                # Fix length: pad or truncate to FIXED_LENGTH\n",
                "                if waveform.shape[1] > FIXED_LENGTH:\n",
                "                    waveform = waveform[:, :FIXED_LENGTH]\n",
                "                elif waveform.shape[1] < FIXED_LENGTH:\n",
                "                    padding = FIXED_LENGTH - waveform.shape[1]\n",
                "                    waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
                "\n",
                "                mel = self.mel(waveform).squeeze(0)\n",
                "                return mel, label\n",
                "                \n",
                "            except Exception as e:\n",
                "                print(f\"Error loading {wav_path}: {e}\")\n",
                "                # Return zeros as fallback\n",
                "                return torch.zeros(64, 130), 0\n",
                "\n",
                "    # --- 5. Model Architecture ---\n",
                "    class AudioCNN(nn.Module):\n",
                "        def __init__(self, num_classes):\n",
                "            super().__init__()\n",
                "\n",
                "            # Convolutional feature extractor\n",
                "            self.features = nn.Sequential(\n",
                "                nn.Conv2d(1, 16, 3, padding=1),\n",
                "                nn.ReLU(),\n",
                "                nn.MaxPool2d(2),\n",
                "                nn.Conv2d(16, 32, 3, padding=1),\n",
                "                nn.ReLU(),\n",
                "                nn.MaxPool2d(2),\n",
                "                nn.AdaptiveAvgPool2d((1, 1))\n",
                "            )\n",
                "\n",
                "            self.classifier = nn.Linear(32, num_classes)\n",
                "\n",
                "        def forward(self, x):\n",
                "            # Add channel dimension\n",
                "            x = x.unsqueeze(1)\n",
                "            x = self.features(x)\n",
                "            x = x.view(x.size(0), -1)\n",
                "            return self.classifier(x)\n",
                "\n",
                "    # --- 6. Main Training Logic ---\n",
                "    try:\n",
                "        device, local_rank, rank, world_size = setup_ddp()\n",
                "\n",
                "        # --- Data Prep ---\n",
                "        # Only Rank 0 downloads the data\n",
                "        if rank == 0:\n",
                "            print(\"Verifying/Downloading dataset...\")\n",
                "            download_gtzan_dataset(data_dir)\n",
                "        \n",
                "        if dist.is_initialized():\n",
                "            dist.barrier()  # Wait for download to finish\n",
                "\n",
                "        # Load dataset\n",
                "        dataset = AudioDataset(data_dir)\n",
                "        \n",
                "        # DDP Sampler handles data sharding across nodes\n",
                "        sampler = DistributedSampler(dataset) if dist.is_initialized() else None\n",
                "        loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=sampler, \n",
                "                          shuffle=(sampler is None), num_workers=0)\n",
                "\n",
                "        # --- Model & Optimizer ---\n",
                "        model = AudioCNN(num_classes=len(dataset.classes)).to(device)\n",
                "        if dist.is_initialized():\n",
                "            model = DDP(model, device_ids=[local_rank] if torch.cuda.is_available() else None)\n",
                "\n",
                "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
                "        criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "        # --- Training Loop ---\n",
                "        print(f\"[Rank {rank}] Starting training on {len(dataset.classes)} classes...\")\n",
                "        for epoch in range(EPOCHS):\n",
                "            model.train()\n",
                "            if sampler: \n",
                "                sampler.set_epoch(epoch)\n",
                "            \n",
                "            total_loss = 0.0\n",
                "            for x, y in loader:\n",
                "                x, y = x.to(device), y.to(device)\n",
                "                \n",
                "                optimizer.zero_grad()\n",
                "                preds = model(x)\n",
                "                loss = criterion(preds, y)\n",
                "                loss.backward()\n",
                "                optimizer.step()\n",
                "                \n",
                "                total_loss += loss.item()\n",
                "            \n",
                "            avg_loss = total_loss / len(loader)\n",
                "            if rank == 0:\n",
                "                print(f\"Epoch {epoch + 1}/{EPOCHS} | Loss: {avg_loss:.4f}\")\n",
                "\n",
                "        # Save model (only rank 0)\n",
                "        if rank == 0:\n",
                "            model_path = output_dir / \"model.pt\"\n",
                "            if dist.is_initialized():\n",
                "                torch.save(model.module.state_dict(), model_path)\n",
                "            else:\n",
                "                torch.save(model.state_dict(), model_path)\n",
                "            print(f\"Model saved to {model_path}\")\n",
                "\n",
                "        cleanup_ddp()\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"[Error] Training failed: {e}\")\n",
                "        cleanup_ddp()\n",
                "        raise"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "57adcfb6",
            "metadata": {},
            "source": [
                "## 3. Run Training Locally\n",
                "\n",
                "Before scaling to a cluster, we test the code locally using the `TrainerClient`. We use the `torch-distributed` runtime which creates a local DDP environment (simulating a cluster node)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4c525f2f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from kubeflow.trainer import CustomTrainer, TrainerClient, LocalProcessBackendConfig\n",
                "\n",
                "# Initialize the client with LocalProcessBackend to run locally\n",
                "client = TrainerClient(\n",
                "    backend_config=LocalProcessBackendConfig(cleanup_venv=True)\n",
                ")\n",
                "\n",
                "# Retrieve the 'torch-distributed' runtime object from the client's registry\n",
                "local_runtime = None\n",
                "for runtime in client.list_runtimes():\n",
                "    if runtime.name == \"torch-distributed\":\n",
                "        local_runtime = runtime\n",
                "        break\n",
                "\n",
                "if not local_runtime:\n",
                "    raise ValueError(\"Local runtime 'torch-distributed' not found\")\n",
                "\n",
                "print(\"Starting local training...\")\n",
                "\n",
                "# Start training\n",
                "job_name = client.train(\n",
                "    trainer=CustomTrainer(\n",
                "        func=train_audio_classification,\n",
                "        # Libraries to install in the local virtual environment\n",
                "        packages_to_install=[\"torch\", \"torchaudio\", \"soundfile\", \"kagglehub\", \"numpy\"],\n",
                "    ),\n",
                "    runtime=local_runtime, \n",
                ")\n",
                "\n",
                "# Stream logs\n",
                "print(f\"\\nJob {job_name} started. Streaming logs...\")\n",
                "for logline in client.get_job_logs(job_name, follow=True):\n",
                "    print(logline, end='')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b0a35fdb",
            "metadata": {},
            "source": [
                "## 4. Run Distributed Training (Kubernetes)\n",
                "\n",
                "Now we scale the job to a Kubernetes cluster. This requires:\n",
                "1. A Kubernetes cluster with the **Kubeflow Training Operator** installed.\n",
                "2. The **TrainingRuntime** CRD (`torch-distributed`) installed on the cluster.\n",
                "3. Access via `~/.kube/config`.\n",
                "\n",
                "Based on your cluster's resources, we use a minimal configuration to avoid resource constraints."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3ff9733a",
            "metadata": {},
            "outputs": [],
            "source": [
                "from kubeflow.trainer import CustomTrainer, TrainerClient\n",
                "\n",
                "# Initialize client (automatically loads ~/.kube/config)\n",
                "client = TrainerClient()\n",
                "\n",
                "print(\"Submitting distributed TrainJob...\")\n",
                "\n",
                "try:\n",
                "    job_name = client.train(\n",
                "        trainer=CustomTrainer(\n",
                "            func=train_audio_classification,\n",
                "            num_nodes=1,  # Start with 1 node\n",
                "            resources_per_node={\n",
                "                \"cpu\": \"1\",         # 1 CPU core\n",
                "                \"memory\": \"2Gi\",    # 2Gi memory\n",
                "            },\n",
                "            packages_to_install=[\"torch\", \"torchaudio\", \"soundfile\", \"kagglehub\", \"numpy\"],\n",
                "        ),\n",
                "        runtime=\"torch-distributed\",\n",
                "    )\n",
                "    print(f\"TrainJob '{job_name}' submitted successfully!\")\n",
                "\n",
                "except Exception as e:\n",
                "    print(f\"Failed to submit TrainJob: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "41859de1",
            "metadata": {},
            "source": [
                "## 5. Check Status & Logs\n",
                "\n",
                "Verify the job status and view real-time logs from the master replica."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b9a85991",
            "metadata": {},
            "outputs": [],
            "source": [
                "!kubectl get trainjobs\n",
                "!kubectl get pods"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "85c4eaff",
            "metadata": {},
            "outputs": [],
            "source": [
                "if 'job_name' in locals():\n",
                "    print(f\"Waiting for job {job_name} to start running...\")\n",
                "    \n",
                "    # Wait for the running status\n",
                "    client.wait_for_job_status(name=job_name, status={\"Running\"}, timeout=300)\n",
                "    \n",
                "    print(f\"Job is running! Streaming logs...\")\n",
                "    for logline in client.get_job_logs(job_name, follow=True):\n",
                "        print(logline, end='')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
