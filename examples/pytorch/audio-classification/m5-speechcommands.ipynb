{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# PyTorch Audio Classification with M5 Network and Speech Commands\n",
    "\n",
    "This example demonstrates how to train an audio classification model using the M5 Network architecture on the Google Speech Commands dataset with PyTorch and Kubeflow Trainer.\n",
    "\n",
    "**Model**: [M5 Network](https://arxiv.org/abs/1610.00087) - A lightweight CNN that processes raw audio waveforms directly using 1D convolutions.\n",
    "\n",
    "**Dataset**: [Speech Commands](https://arxiv.org/abs/1804.03209) - One-second audio clips of 35 spoken words (\"yes\", \"no\", \"up\", \"down\", etc.).\n",
    "\n",
    "This notebook shows how to run distributed training locally and scale to a Kubernetes cluster using Kubeflow Trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-sdk",
   "metadata": {},
   "source": [
    "## Install the Kubeflow SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pip-install-sdk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kubeflow in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (0.2.1)\n",
      "Requirement already satisfied: kubeflow-katib-api>=0.19.0 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubeflow) (0.19.0)\n",
      "Requirement already satisfied: kubeflow-trainer-api>=2.0.0 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubeflow) (2.1.0)\n",
      "Requirement already satisfied: kubernetes>=27.2.0 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubeflow) (34.1.0)\n",
      "Requirement already satisfied: pydantic>=2.10.0 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubeflow) (2.12.5)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubernetes>=27.2.0->kubeflow) (2025.11.12)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubernetes>=27.2.0->kubeflow) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubernetes>=27.2.0->kubeflow) (2.9.0.post0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubernetes>=27.2.0->kubeflow) (6.0.3)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubernetes>=27.2.0->kubeflow) (2.45.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubernetes>=27.2.0->kubeflow) (1.9.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubernetes>=27.2.0->kubeflow) (2.32.5)\n",
      "Requirement already satisfied: requests-oauthlib in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubernetes>=27.2.0->kubeflow) (2.0.0)\n",
      "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubernetes>=27.2.0->kubeflow) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from kubernetes>=27.2.0->kubeflow) (0.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=27.2.0->kubeflow) (6.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=27.2.0->kubeflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=27.2.0->kubeflow) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=27.2.0->kubeflow) (0.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from pydantic>=2.10.0->kubeflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from pydantic>=2.10.0->kubeflow) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from pydantic>=2.10.0->kubeflow) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from pydantic>=2.10.0->kubeflow) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from requests->kubernetes>=27.2.0->kubeflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from requests->kubernetes>=27.2.0->kubeflow) (3.11)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from requests-oauthlib->kubernetes>=27.2.0->kubeflow) (3.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U kubeflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-deps",
   "metadata": {},
   "source": [
    "## Install PyTorch Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pip-install-deps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchaudio in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (3.20.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/projects/kubeflow/trainer/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define-training-func",
   "metadata": {},
   "source": [
    "## Define the Training Function\n",
    "\n",
    "This function includes the M5 model architecture, data loading, and distributed training logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "training-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_m5_speechcommands(batch_size: int = 256, epochs: int = 2, lr: float = 0.01):\n",
    "    import os\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    import torch.optim as optim\n",
    "    import torch.distributed as dist\n",
    "    import torchaudio\n",
    "    from torchaudio.datasets import SPEECHCOMMANDS\n",
    "    from torch.utils.data import DataLoader, DistributedSampler\n",
    "\n",
    "    # M5 Network - lightweight CNN for audio classification\n",
    "    class M5(nn.Module):\n",
    "        def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "            super().__init__()\n",
    "            # 4 conv blocks with increasing channels\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride),\n",
    "                nn.BatchNorm1d(n_channel),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(4),\n",
    "                nn.Conv1d(n_channel, n_channel, kernel_size=3),\n",
    "                nn.BatchNorm1d(n_channel),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(4),\n",
    "                nn.Conv1d(n_channel, 2*n_channel, kernel_size=3),\n",
    "                nn.BatchNorm1d(2*n_channel),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(4),\n",
    "                nn.Conv1d(2*n_channel, 2*n_channel, kernel_size=3),\n",
    "                nn.BatchNorm1d(2*n_channel),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(4)\n",
    "            )\n",
    "            self.classifier = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.feature_extractor(x)\n",
    "            x = F.avg_pool1d(x, x.shape[-1]).permute(0, 2, 1)\n",
    "            return F.log_softmax(self.classifier(x), dim=2)\n",
    "\n",
    "    # Custom collate to handle variable-length audio samples\n",
    "    def collate_fn(batch):\n",
    "        tensors, targets = [], []\n",
    "        for waveform, _, label, *_ in batch:\n",
    "            tensors += [waveform.t()]\n",
    "            targets += [torch.tensor(labels.index(label))]\n",
    "        # Pad to same length\n",
    "        tensors = torch.nn.utils.rnn.pad_sequence(\n",
    "            tensors, batch_first=True, padding_value=0.\n",
    "        ).permute(0, 2, 1)\n",
    "        return tensors, torch.stack(targets)\n",
    "\n",
    "    # Setup distributed training\n",
    "    device_type, backend = (\n",
    "        (\"cuda\", \"nccl\") if torch.cuda.is_available() else (\"cpu\", \"gloo\")\n",
    "    )\n",
    "    print(f\"Using Device: {device_type}, Backend: {backend}\")\n",
    "    \n",
    "    local_rank = int(os.getenv(\"LOCAL_RANK\", 0))\n",
    "    dist.init_process_group(backend=backend)\n",
    "    print(\n",
    "        f\"Distributed Training - WORLD_SIZE: {dist.get_world_size()}, \"\n",
    "        f\"RANK: {dist.get_rank()}, LOCAL_RANK: {local_rank}\"\n",
    "    )\n",
    "    \n",
    "    device = torch.device(f\"{device_type}:{local_rank}\")\n",
    "\n",
    "    # Download dataset on rank 0 only to avoid conflicts\n",
    "    if dist.get_rank() == 0:\n",
    "        train_set = SPEECHCOMMANDS(\"./\", download=True, subset=\"training\")\n",
    "    dist.barrier()\n",
    "    \n",
    "    train_set = SPEECHCOMMANDS(\"./\", download=False, subset=\"training\")\n",
    "    labels = sorted(list(set(d[2] for d in train_set)))\n",
    "    print(f\"Number of classes: {len(labels)}\")\n",
    "    \n",
    "    # Resample to 8kHz for faster processing\n",
    "    waveform, sample_rate, *_ = train_set[0]\n",
    "    resampler = torchaudio.transforms.Resample(sample_rate, 8000).to(device)\n",
    "    \n",
    "    # Distributed data loader\n",
    "    sampler = DistributedSampler(train_set)\n",
    "    loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=1 if device_type == \"cuda\" else 0\n",
    "    )\n",
    "\n",
    "    # Initialize model with DDP\n",
    "    model = M5(n_input=waveform.shape[0], n_output=len(labels)).to(device)\n",
    "    model = nn.parallel.DistributedDataParallel(model)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    dist.barrier()\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        sampler.set_epoch(epoch)  # Ensure different shuffle each epoch\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            data = resampler(data.to(device))\n",
    "            target = target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output.squeeze(), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Log from rank 0 only\n",
    "            if batch_idx % 20 == 0 and dist.get_rank() == 0:\n",
    "                print(\n",
    "                    f\"Epoch: {epoch} \"\n",
    "                    f\"[{batch_idx * len(data) * dist.get_world_size()}/{len(train_set)} \"\n",
    "                    f\"({100.0 * batch_idx / len(loader):.0f}%)]\\t\"\n",
    "                    f\"Loss: {loss.item():.6f}\"\n",
    "                )\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    dist.barrier()\n",
    "    if dist.get_rank() == 0:\n",
    "        print(\"Training Complete\")\n",
    "    \n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scale-trainjob",
   "metadata": {},
   "source": [
    "## Scale with Kubeflow TrainJob\n",
    "\n",
    "Now scale the training across multiple nodes on your Kubernetes cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "init-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.trainer import CustomTrainer, TrainerClient\n",
    "\n",
    "client = TrainerClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "list-runtimes",
   "metadata": {},
   "source": [
    "## List Available Training Runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "list-runtimes-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime(name='deepspeed-distributed', trainer=RuntimeTrainer(trainer_type=<TrainerType.CUSTOM_TRAINER: 'CustomTrainer'>, framework='deepspeed', image='ghcr.io/kubeflow/trainer/deepspeed-runtime:v2.1.0', num_nodes=1, device='Unknown', device_count='1'), pretrained_model=None)\n",
      "Runtime(name='mlx-distributed', trainer=RuntimeTrainer(trainer_type=<TrainerType.CUSTOM_TRAINER: 'CustomTrainer'>, framework='mlx', image='ghcr.io/kubeflow/trainer/mlx-runtime:v2.1.0', num_nodes=1, device='Unknown', device_count='1'), pretrained_model=None)\n",
      "Runtime(name='torch-distributed', trainer=RuntimeTrainer(trainer_type=<TrainerType.CUSTOM_TRAINER: 'CustomTrainer'>, framework='torch', image='pytorch/pytorch:2.7.1-cuda12.8-cudnn9-runtime', num_nodes=1, device='Unknown', device_count='Unknown'), pretrained_model=None)\n",
      "Runtime(name='torchtune-llama3.2-1b', trainer=RuntimeTrainer(trainer_type=<TrainerType.BUILTIN_TRAINER: 'BuiltinTrainer'>, framework='torchtune', image='ghcr.io/kubeflow/trainer/torchtune-trainer:v2.1.0', num_nodes=1, device='gpu', device_count='2.0'), pretrained_model=None)\n",
      "Runtime(name='torchtune-llama3.2-3b', trainer=RuntimeTrainer(trainer_type=<TrainerType.BUILTIN_TRAINER: 'BuiltinTrainer'>, framework='torchtune', image='ghcr.io/kubeflow/trainer/torchtune-trainer:v2.1.0', num_nodes=1, device='gpu', device_count='2.0'), pretrained_model=None)\n",
      "Runtime(name='torchtune-qwen2.5-1.5b', trainer=RuntimeTrainer(trainer_type=<TrainerType.BUILTIN_TRAINER: 'BuiltinTrainer'>, framework='torchtune', image='ghcr.io/kubeflow/trainer/torchtune-trainer:v2.1.0', num_nodes=1, device='gpu', device_count='2.0'), pretrained_model=None)\n"
     ]
    }
   ],
   "source": [
    "for runtime in client.list_runtimes():\n",
    "    print(runtime)\n",
    "    if runtime.name == \"torch-distributed\":\n",
    "        torch_runtime = runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-distributed",
   "metadata": {},
   "source": [
    "## Submit Distributed Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "submit-job-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: nb39c911399d\n"
     ]
    }
   ],
   "source": [
    "job_id = client.train(\n",
    "    trainer=CustomTrainer(\n",
    "        func=train_m5_speechcommands,\n",
    "        func_args={\"epochs\": 5, \"batch_size\": 256, \"lr\": 0.01},\n",
    "        num_nodes=1,\n",
    "        packages_to_install=[\"torchaudio\", \"torch\", \"soundfile\"],\n",
    "        resources_per_node={\n",
    "            \"cpu\": \"8\",\n",
    "            \"memory\": \"32Gi\",\n",
    "            # Comment for CPU only node\n",
    "            \"nvidia.com/gpu\": 1,  # Request 1 GPU per node\n",
    "        },\n",
    "    ),\n",
    "    runtime=torch_runtime,\n",
    ")\n",
    "print(f\"Job ID: {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "check-steps",
   "metadata": {},
   "source": [
    "## Monitor Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wait-running",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainJob(name='nb39c911399d', runtime=Runtime(name='torch-distributed', trainer=RuntimeTrainer(trainer_type=<TrainerType.CUSTOM_TRAINER: 'CustomTrainer'>, framework='torch', image='pytorch/pytorch:2.7.1-cuda12.8-cudnn9-runtime', num_nodes=1, device='Unknown', device_count='Unknown'), pretrained_model=None), steps=[Step(name='node-0', status='Running', pod_name='nb39c911399d-node-0-0-lgsnk', device='gpu', device_count='1')], num_nodes=1, creation_timestamp=datetime.datetime(2026, 1, 3, 21, 26, 29, tzinfo=TzInfo(0)), status='Running')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.wait_for_job_status(name=job_id, status={\"Running\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "show-steps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: node-0, Status: Running, Devices: gpu x 1\n"
     ]
    }
   ],
   "source": [
    "for step in client.get_job(name=job_id).steps:\n",
    "    print(f\"Step: {step.name}, Status: {step.status}, Devices: {step.device} x {step.device_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "watch-logs",
   "metadata": {},
   "source": [
    "## View Training Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "monitor-logs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "W0103 21:26:32.268000 1 site-packages/torch/distributed/run.py:766] \n",
      "W0103 21:26:32.268000 1 site-packages/torch/distributed/run.py:766] *****************************************\n",
      "W0103 21:26:32.268000 1 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0103 21:26:32.268000 1 site-packages/torch/distributed/run.py:766] *****************************************\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Using Device: cpu, Backend: gloo\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 1, LOCAL_RANK: 1\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 2, LOCAL_RANK: 2Distributed Training - WORLD_SIZE: 30, RANK: 3, LOCAL_RANK: 3\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 6, LOCAL_RANK: 6\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 9, LOCAL_RANK: 9\n",
      "\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 11, LOCAL_RANK: 11\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 8, LOCAL_RANK: 8\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 19, LOCAL_RANK: 19Distributed Training - WORLD_SIZE: 30, RANK: 10, LOCAL_RANK: 10\n",
      "\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 15, LOCAL_RANK: 15\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 24, LOCAL_RANK: 24\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 16, LOCAL_RANK: 16\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 22, LOCAL_RANK: 22\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 25, LOCAL_RANK: 25\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 0, LOCAL_RANK: 0\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 4, LOCAL_RANK: 4\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 5, LOCAL_RANK: 5\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 7, LOCAL_RANK: 7\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 12, LOCAL_RANK: 12\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 13, LOCAL_RANK: 13\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 14, LOCAL_RANK: 14\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 17, LOCAL_RANK: 17\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 18, LOCAL_RANK: 18\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 20, LOCAL_RANK: 20\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 21, LOCAL_RANK: 21\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 23, LOCAL_RANK: 23\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 26, LOCAL_RANK: 26\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 27, LOCAL_RANK: 27\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 28, LOCAL_RANK: 28\n",
      "Distributed Training - WORLD_SIZE: 30, RANK: 29, LOCAL_RANK: 29\n",
      "100%|██████████| 2.26G/2.26G [00:09<00:00, 263MB/s]\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Number of classes: 35\n",
      "Epoch: 1 [0/84843 (0%)]\tLoss: 3.828651\n",
      "Epoch: 2 [0/84843 (0%)]\tLoss: 3.079055\n",
      "Epoch: 3 [0/84843 (0%)]\tLoss: 2.339605\n",
      "Epoch: 4 [0/84843 (0%)]\tLoss: 1.994498\n",
      "Epoch: 5 [0/84843 (0%)]\tLoss: 1.792782\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "for logline in client.get_job_logs(job_id, follow=True):\n",
    "    print(logline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "delete-job",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_job(job_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
