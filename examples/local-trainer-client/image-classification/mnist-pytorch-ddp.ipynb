{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Using `LocalTrainerClient` for MNIST image classification with PyTorch DDP\n",
    "\n",
    "This notebook uses the `LocalTrainerClient` to train an image classification model using the MNIST fashion dataset.\n",
    "\n",
    "The `LocalTrainerClient` runs training jobs locally in Docker containers. No Kubernetes cluster is required."
   ],
   "id": "a60e2c2113c5457e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Install the KubeFlow SDK",
   "id": "84e97d6c70c9b899"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install git+https://github.com/kubeflow/sdk.git@main#subdirectory=python",
   "id": "5744f170c5b80ed0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define the training function\n",
    "\n",
    "This function trains a CNN model using the Fashion MNIST dataset.\n"
   ],
   "id": "a9ec88862250e5fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_pytorch():\n",
    "    import os\n",
    "\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    from torchvision import datasets, transforms\n",
    "    import torch.distributed as dist\n",
    "    from torch.utils.data import DataLoader, DistributedSampler\n",
    "\n",
    "    # [1] Configure CPU/GPU device and distributed backend.\n",
    "    # Kubeflow Trainer will automatically configure the distributed environment.\n",
    "    device, backend = (\"cuda\", \"nccl\") if torch.cuda.is_available() else (\"cpu\", \"gloo\")\n",
    "    dist.init_process_group(backend=backend)\n",
    "\n",
    "    local_rank = int(os.getenv(\"LOCAL_RANK\", 0))\n",
    "    print(\n",
    "        \"Distributed Training with WORLD_SIZE: {}, RANK: {}, LOCAL_RANK: {}.\".format(\n",
    "            dist.get_world_size(),\n",
    "            dist.get_rank(),\n",
    "            local_rank,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # [2] Define PyTorch CNN Model to be trained.\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "            self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "            self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
    "            self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = F.max_pool2d(x, 2, 2)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = F.max_pool2d(x, 2, 2)\n",
    "            x = x.view(-1, 4 * 4 * 50)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "    # [3] Attach model to the correct device.\n",
    "    device = torch.device(f\"{device}:{local_rank}\")\n",
    "    model = nn.parallel.DistributedDataParallel(Net().to(device))\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "    # [4] Get the Fashion-MNIST dataset and distributed it across all available devices.\n",
    "    dataset = datasets.FashionMNIST(\n",
    "        \"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor()]),\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=100,\n",
    "        sampler=DistributedSampler(dataset),\n",
    "    )\n",
    "\n",
    "    # [5] Define the training loop.\n",
    "    for epoch in range(3):\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            # Attach tensors to the device.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = F.nll_loss(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0 and dist.get_rank() == 0:\n",
    "                print(\n",
    "                    \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                        epoch,\n",
    "                        batch_idx * len(inputs),\n",
    "                        len(train_loader.dataset),\n",
    "                        100.0 * batch_idx / len(train_loader),\n",
    "                        loss.item(),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    # Wait for the training to complete and destroy to PyTorch distributed process group.\n",
    "    dist.barrier()\n",
    "    if dist.get_rank() == 0:\n",
    "        print(\"Training is finished\")\n",
    "    dist.destroy_process_group()"
   ],
   "id": "d6a21456689f159e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create the trainer client",
   "id": "7ec4a4f4798262fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The `LocalTrainerClient` exposes the same interface as the `TrainerClient`.\n",
    "\n",
    "When you wish to move your job to a Kubernetes cluster, simply change the\n",
    "training client -- the rest of the notebook will work without modification."
   ],
   "id": "f96aac49d86012aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "from kubeflow.trainer import LocalTrainerClient, TrainerClient, CustomTrainer\n",
    "\n",
    "exec_mode = os.getenv(\"KUBEFLOW_TRAINER_EXEC_MODE\", \"local\")\n",
    "\n",
    "if exec_mode == \"local\":\n",
    "    client = LocalTrainerClient()\n",
    "else:\n",
    "    client = TrainerClient()"
   ],
   "id": "8fd9a027b2fd0bb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## List runtimes\n",
    "\n",
    "Predefined training runtimes are included as part of the package. Currently only the `torch-distributed` runtime is included."
   ],
   "id": "330f4e46f7589c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "client.list_runtimes()",
   "id": "5bed41c85c10693f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get runtime",
   "id": "180fd7d4363c7663"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "runtime = client.get_runtime(\"torch-distributed\")",
   "id": "710945a87d441f3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Start the training job\n",
    "\n",
    "This job uses the `torch-distrbuted` runtime to run the `train_pytorch` training function. The job runs on four worker node containers."
   ],
   "id": "599356d3f9822f34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "job_name = client.train(\n",
    "        runtime=runtime,\n",
    "        trainer=CustomTrainer(\n",
    "            func=train_pytorch,\n",
    "            num_nodes=4,\n",
    "        )\n",
    "    )"
   ],
   "id": "f87c8b73a118aa7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Follow job logs",
   "id": "a9808de7c45c4b60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "_ = client.get_job_logs(job_name, follow=True)",
   "id": "7eea34f905c73f35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Optional: Examine Docker resources\n",
    "\n",
    "In a terminal, run the following to list the containers running the training job:\n",
    "\n",
    "```shell\n",
    "docker ps -a --filter label=trainer.kubeflow.org/train-job-name\n",
    "```\n",
    "\n",
    "Example output:\n",
    "\n",
    "```\n",
    "CONTAINER ID   IMAGE                                           COMMAND                   CREATED          STATUS                     PORTS     NAMES\n",
    "e116e42af00a   pytorch/pytorch:2.5.0-cuda12.4-cudnn9-runtime   \"bash -c '\\nread -r -…\"   11 minutes ago   Exited (0) 7 minutes ago             kubeflow-trainer-l20b00d08df5-3\n",
    "0f9d891edd74   pytorch/pytorch:2.5.0-cuda12.4-cudnn9-runtime   \"bash -c '\\nread -r -…\"   11 minutes ago   Exited (0) 7 minutes ago             kubeflow-trainer-l20b00d08df5-2\n",
    "1672a222d360   pytorch/pytorch:2.5.0-cuda12.4-cudnn9-runtime   \"bash -c '\\nread -r -…\"   11 minutes ago   Exited (0) 7 minutes ago             kubeflow-trainer-l20b00d08df5-1\n",
    "e1f11b5fad3c   pytorch/pytorch:2.5.0-cuda12.4-cudnn9-runtime   \"bash -c '\\nread -r -…\"   11 minutes ago   Exited (0) 7 minutes ago             kubeflow-trainer-l20b00d08df5-0\n",
    "```\n",
    "\n",
    "Run the following to see the Docker network:\n",
    "\n",
    "```shell\n",
    "docker network ls --filter label=trainer.kubeflow.org/train-job-name\n",
    "```\n",
    "\n",
    "Example output:\n",
    "\n",
    "```\n",
    "NETWORK ID     NAME                            DRIVER    SCOPE\n",
    "157a6ed5752f   kubeflow-trainer-l20b00d08df5   bridge    local\n",
    "```"
   ],
   "id": "904e0e5b7c5a6bd1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Delete the job",
   "id": "d85dc06233c3a261"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "client.delete_job(job_name)",
   "id": "b86744e74c6d5c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
